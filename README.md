# E-Commerce Data Analysis LangGraph Agent

A sophisticated AI agent built with LangGraph that analyzes e-commerce data from Google BigQuery's public dataset and generates actionable business insights using Google Gemini.

## ğŸ¯ Features

- **Intelligent Query Understanding**: Automatically classifies user questions into analysis categories
- **Dynamic SQL Generation**: Creates optimized BigQuery SQL queries based on natural language requests
- **Comprehensive Analysis Types**:
  - Customer segmentation and behavior analysis
  - Product performance and recommendations
  - Sales trends and seasonality patterns
  - Geographic sales distributions
- **Error Recovery**: Automatic retry logic with SQL error correction
- **Interactive CLI**: User-friendly command-line interface with progress indicators
- **Rate Limiting**: Built-in handling for API rate limits with exponential backoff

## ğŸ—ï¸ Architecture

The agent uses LangGraph's state graph pattern for explicit control flow:

```
User Query
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Analyze Request â”‚ â† Determine intent & analysis type
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Generate SQL   â”‚ â† Create BigQuery SQL query
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Execute Query   â”‚ â† Run query on BigQuery
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
    â”œâ”€ Error? â†’ Retry (max 2x) â†’ Generate SQL
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Analyze Results â”‚ â† Generate business insights
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Respond      â”‚ â† Format & return to user
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Components

- **State Management** (`agent/state.py`): Typed state tracking query context and results
- **Graph Nodes** (`agent/nodes.py`): Core logic for each processing step
- **Graph Builder** (`agent/graph.py`): StateGraph construction with conditional routing
- **LLM Integration** (`llm/gemini_client.py`): Gemini configuration with retry logic
- **BigQuery Tools** (`tools/bigquery_tools.py`): Query execution and schema retrieval
- **System Prompts** (`prompts/system_prompts.py`): Carefully crafted prompts for each step
- **Testing** (`tests/test_all_analysis_types.py`): Testing the whole agent flow for all 4 analysis types

## ğŸ“‹ Prerequisites

- Python 3.9+
- Google Cloud account with BigQuery access
- Google AI Studio API key (free tier available)

## ğŸš€ Setup

### 1. Clone the Repository

```bash
git clone [<repository-url>](https://github.com/gerliron18/OpsFleet.git)
cd OpsFleet
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. Configure Google Cloud

Authenticate with Google Cloud for BigQuery access:

```bash
# Install Google Cloud SDK if not already installed
# Download from: https://cloud.google.com/sdk/docs/install

# Authenticate
gcloud auth application-default login

# Set your project (optional)
gcloud config set project YOUR_PROJECT_ID
```

### 4. Get Google AI Studio API Key

1. Visit [Google AI Studio](https://makersuite.google.com/app/apikey)
2. Create a new API key
3. Copy the API key

### 5. Configure Environment Variables

Create a `.env` file in the project root:

```bash
cp env.example .env
```

Edit `.env` and add your API key:

```env
# Required: Google AI Studio API Key
GOOGLE_API_KEY=your_api_key_here

# Optional: GCP Project ID (uses default if not set)
# GCP_PROJECT_ID=your_project_id

# Optional: BigQuery Dataset (default shown)
BIGQUERY_DATASET=bigquery-public-data.thelook_ecommerce

# Optional: Gemini Model (default: gemini-2.5-flash)
# GEMINI_MODEL=gemini-2.5-flash

# Optional: Logging Level (default: INFO)
LOG_LEVEL=INFO
```

## ğŸ’» Usage

### Start the Interactive CLI

```bash
python main.py
```

### Example Queries

#### Customer Segmentation
```
What are the top customer segments by purchase frequency?
Show me RFM analysis for customers
Which customers have the highest lifetime value?
```

#### Product Performance
```
What are the top 10 best-selling products?
Show me product performance by category
Which products have the highest profit margins?
```

#### Sales Trends
```
Show me monthly sales trends for the last year
Analyze sales seasonality patterns
What were the sales trends during holiday seasons?
```

#### Geographic Analysis
```
Which countries generate the most revenue?
Show me sales distribution by region
What are the top cities by order volume?
```

### CLI Commands

- Type your question in natural language
- `help` or `?` - Show help information
- `exit`, `quit`, `q`, `bye` - Exit the application

## ğŸ§ª Example Session

```
You: What are the top 5 selling products?

ğŸ¤” Analyzing your question...
ğŸ” Processing query...

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ğŸ“Š Analysis Results:

Summary:
The top 5 selling products based on order count show strong 
performance across different categories, with Product A leading 
significantly.

Detailed Findings:
1. Product A (Electronics): 1,234 orders, $45,678 revenue
2. Product B (Clothing): 1,156 orders, $38,920 revenue
...

Recommendations:
- Increase inventory for top-performing products
- Consider bundling strategies for related items
- Analyze why Product A outperforms others

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

## ğŸ“Š Dataset Information

The agent queries the public BigQuery dataset: `bigquery-public-data.thelook_ecommerce`

### Available Tables

- **orders**: Order information (order_id, user_id, status, created_at, etc.)
- **order_items**: Line items (order_id, product_id, sale_price, etc.)
- **products**: Product catalog (product_id, name, brand, category, price, etc.)
- **users**: Customer data (user_id, name, email, age, gender, city, country, etc.)

## ğŸ›¡ï¸ Error Handling

The agent includes comprehensive error handling:

- **SQL Errors**: Automatically attempts to fix and retry queries (up to 2 retries)
- **Rate Limits**: Exponential backoff for Gemini API rate limits
- **Query Validation**: Prevents dangerous operations (DROP, DELETE, etc.)
- **Connection Issues**: Clear error messages with troubleshooting steps

## ğŸ§© Technical Decisions

### Why Gemini?
- Free tier with generous quotas
- Excellent SQL generation capabilities
- Strong natural language understanding
- Easy integration with LangChain

### Why LangGraph?
- Explicit control over agent flow (vs. fully autonomous agents)
- Easy debugging with visible state transitions
- Conditional routing for error recovery
- Better reliability for production use

### Error Recovery Strategy
- Multi-layer approach: retry API calls, reformulate SQL on errors
- Non-retryable errors (auth, permissions) fail immediately
- User-friendly error messages with context

## ğŸ“ Project Structure

```
OpsFleet/
â”œâ”€â”€ main.py                # CLI entry point
â”œâ”€â”€ bq_client.py           # BigQuery client wrapper
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ env.example            # Environment variables template
â”œâ”€â”€ README.md              # This file
â”œâ”€â”€ setup.sh               # Setup dependencies and env
â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ state.py          # State definitions
â”‚   â”œâ”€â”€ nodes.py          # Graph node implementations
â”‚   â””â”€â”€ graph.py          # StateGraph construction
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ bigquery_tools.py # BigQuery tool wrappers
â”œâ”€â”€ llm/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ gemini_client.py  # Gemini LLM configuration
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ system_prompts.py # Agent system prompts
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_all_analysis_types.py   # Integration test for all 4 analysis types
â”‚   â”œâ”€â”€ test_bigquery_tools.py       # Unit test for big-query tools
â”‚   â”œâ”€â”€ test_integration.py          # Basic integration test
â”‚   â”œâ”€â”€ test_nodes.py                # Unit test for nodes
â”‚   â”œâ”€â”€ test_prompts.py              # Unit test for prompts
â”‚   â””â”€â”€ test_state.py                # Unit test for state
â””â”€â”€ docs/
    â”œâ”€â”€ architecture.md    # Detailed architecture documentation
    â””â”€â”€ architecture.txt   # Architecture diagram
```

## ğŸ› Troubleshooting

### BigQuery Authentication Issues

```bash
# Re-authenticate
gcloud auth application-default login

# Verify authentication
gcloud auth application-default print-access-token
```

### API Key Issues

- Ensure `.env` file exists and contains `GOOGLE_API_KEY`
- Verify the API key is valid in [Google AI Studio](https://makersuite.google.com/app/apikey)
- Check for rate limit errors (free tier: 15 RPM)

### Module Import Errors

```bash
# Reinstall dependencies
pip install -r requirements.txt --upgrade
```

## ğŸ“ˆ Performance Notes

- **First Query**: ~5-10 seconds (includes schema retrieval)
- **Subsequent Queries**: ~3-5 seconds (cached schemas)
- **BigQuery Compute**: Uses free tier (1TB/month)
- **Gemini API**: Free tier limits apply (15 requests/minute)

## ğŸ”’ Security

- SQL query validation prevents dangerous operations
- Only SELECT queries are allowed
- No write access to BigQuery
- API keys stored in `.env` (not committed to git)

## ğŸ“ License

This project is created for educational purposes as part of a technical assignment.

## ğŸ™‹ Support

For issues or questions:
1. Check the troubleshooting section
2. Review the architecture documentation in `docs/`
3. Enable DEBUG logging: `LOG_LEVEL=DEBUG` in `.env`
